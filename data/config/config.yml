general:
  name:
#  scenario: 'simple'
#  scenario: 'hard'
#  scenario: 'point_robot_easy'
#  scenario: 'point_robot_easy2'
#  scenario: 'point_robot_easy2_transposed'
  scenario: 'point_robot_box_0.2'
#  scenario: 'point_robot_box_0.8'
#  scenario: 'point_robot_box_1.6'
#  scenario: 'point_robot_corridor'
#  scenario: 'point_robot_hard_corridors'
  gpu_usage: 0.2
  write_summaries_every: 7
  training_cycles: 1000000
  train_episodes_per_cycle: 100
#  train_episodes_per_cycle: 1000
#  test_episodes: 1000
#  test_episodes: 1
  test_episodes: 100
#  episodes_per_cycle: 3
  save_every_cycles: 1000000
  cycles_per_trajectory_print: 1000000
  test_frequency: 3

cost:
#  collision_cost: 10.0
#  collision_cost: 1000.0
  collision_cost: 200.0
#  collision_cost: 20.0
  free_cost: 1.0
  type: 'linear'
#  type: 'huber'
#  type: 'square'
  huber_loss_delta: 1.0

model:
  levels: 2
#  levels: 5
  starting_level: 1
#  train_levels: 'all-below'
  train_levels: 'topmost'
#  init_from_lower_level: True
  init_from_lower_level: False
  batch_size: 20000
  decrease_learn_rate_if_static_success: 100
#  decrease_learn_rate_if_static_success: 100
#  decrease_learn_rate_if_static_success: 25
#  decrease_learn_rate_if_static_success: 3
#  decrease_learn_rate_if_static_success: 2
#  stop_training_after_learn_rate_decrease: 10
  stop_training_after_learn_rate_decrease: 3
#  stop_training_after_learn_rate_decrease: 2
#  stop_training_after_learn_rate_decrease: 1
#  gain: 'full-traj'
  gain: 'future-only'

policy:
#  learning_rate: 0.0001
#  learning_rate: 0.0001
  learning_rate: 0.00001
#  learning_rate: 0.0005
#  learning_rate: 0.005
#  learning_rate: 0.001
#  learning_rate_decrease_rate: 1.
#  learning_rate_decrease_rate: 0.8
  learning_rate_decrease_rate: 0.8
  learning_rate_minimum: 0.0000000001
#  gradient_limit: 0.0
#  gradient_limit: 1000.0 # for cost 100
#  gradient_limit: 10000.0 # for cost 200
  gradient_limit: 1400.0
#  layers: [400, 400, 400, 400]
#  layers: [1000, 1000, 1000]
  layers: [1000, 1000]
#  layers: [100, 100, 100, 100]
#  layers: [20, 20]
#  layers: [20, 20, 20]
#  layers: [5, 5]
#  layers: [2]
#  activation: 'elu'
#  activation: 'relu'
  activation: 'tanh'
#  base_std: 0.01
  base_std: 0.05
#  base_std: 0.5
#  base_std: 0.1
#  log_prob_ignore_pdf: 0.0
#  log_prob_ignore_pdf: 0.000000001
#  log_prob_ignore_pdf: 0.001
#  log_prob_ignore_pdf: 0.01
  learn_std: False
#  learn_std: True
  value_loss_threshold: 0.01

value_function:
  learning_rate: 0.001
  learning_rate_decrease_rate: 0.8
  learning_rate_minimum: 0.0000000001
#  gradient_limit: 0.0
  gradient_limit: 800.0
#  layers: [400, 400, 400, 400, 400, 400]
  layers: [100, 100, 100, 100]
#  layers: [20, 20, 20]
#  layers: [5]
#  layers: [5, 5]
  activation: 'elu'
#  activation: 'relu'
#  activation: 'tanh'
  max_straight_updates: 1000