general:
  name:
#  scenario: 'point_robot_easy'
#  scenario: 'point_robot_easy2'
#  scenario: 'point_robot_easy2_transposed'
#  scenario: 'point_robot_box_0.2'
#  scenario: 'point_robot_box_0.8'
#  scenario: 'point_robot_box_1.6'
#  scenario: 'point_robot_corridor'
#  scenario: 'point_robot_hard_corridors'
#  scenario: panda_no_obs
#  scenario: panda_no_obs_fixed_start
#  scenario: panda_easy
#  scenario: panda_easy_fixed_start
#  scenario: panda_hard
#  scenario: panda_poles
  scenario: disks
  gpu_usage: 0.2
  training_cycles_per_level: 30000
  train_episodes_per_cycle: 30
#  train_episodes_per_cycle: 120
  save_every_cycles: 1000000
  cycles_per_trajectory_print: 1000000
  test_frequency: 3
#  test_frequency: 1
  limit_workers:

cost:
  collision_cost: 100.0
  is_constant_collision_cost: False
  free_cost: 1.0
  is_constant_free_cost: False
  type: 'linear'
#  type: 'huber'
#  type: 'square'
  huber_loss_delta: 1.0

model:
  number_of_middle_states: 1
  batch_size: 10
  reset_best_every: 0
#  reset_best_every: 50
  decrease_learn_rate_if_static_success: 40
  restore_on_decrease: True
#  restore_on_decrease: False
  stop_training_after_learn_rate_decrease: 3
#  gain: 'full-traj'
  gain: 'future-only'
#  repeat_train_trajectories: 10
  repeat_train_trajectories: 40
  consecutive_optimization_steps: 1

policy:
  learning_rate: 0.005
  learning_rate_decrease_rate: 1.
#  learning_rate_decrease_rate: 0.8
  learning_rate_minimum: 0.0005
  gradient_limit: 10.0
#  gradient_limit: 100.0
  gradient_limit_quantile:
#  gradient_limit_quantile: 0.5
  gradient_history_limit: 0
#  gradient_history_limit: 100
#  include_middle_state_as_input: True
  include_middle_state_as_input: False
#  layers: [5, 5]
  layers: [20, 20, 20]
#  activation: 'elu'
#  activation: 'relu'
  activation: 'tanh'
  base_std: 0.05
  decrease_std_every: 100
  std_decrease_rate: 0.95
#  distance_adaptive_std: False
  distance_adaptive_std: True
  learn_std: False
#  learn_std: True
  max_entropy_coefficient: 1.
  #  bias_activation_is_tanh: True
  bias_activation_is_tanh: False
  bias_around_midpoint: True
  #  bias_around_midpoint: False
  ppo_epsilon: 0.05

value_estimator:
  learning_rate: 0.005
#  learning_rate: 0.005
  learning_rate_decrease_rate: 1.
#  learning_rate_decrease_rate: 0.8
  learning_rate_minimum: 0.00025
#  gradient_limit: 0.0
  gradient_limit: 100.0
  gradient_limit_quantile:
#  gradient_limit_quantile: 0.9
  gradient_history_limit: 0
#  gradient_history_limit: 100
#  layers: [5, 5]
#  layers: [50, 50,
  layers: [20, 20, 20]
  activation: 'elu'
#  activation: 'relu'
#  activation: 'tanh'

curriculum:
#  use: True
  use: False
  times_std_start_coefficient: 2.
  raise_times: 1.1
  raise_when_train_above: 0.95

gradient_checker:
#  enable: True
  enable: False
  gradient_points_to_sample: 100